#written by: Avishkar giri


import math as ma;
import matplotlib.pyplot as mat;
import numpy as nu;
import pandas as pa;
import scipy.stats as sci;

import seaborn as se;
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics;
import seaborn as sea;
import statsmodels.api as stat;
from sklearn.preprocessing import PowerTransformer;
from sklearn.preprocessing import StandardScaler;

#Reading data from .csv file
df_dataset1=pa.read_csv("dataset1.csv");
df_dataset2=pa.read_csv("dataset2.csv");



#Calculate total number of bats landing number
no_of_bats=0;
no_of_bats=sum(df_dataset2['bat_landing_number'].values);

print("total number of bats landing is", no_of_bats);

#Calculate total number of rats arrival number
no_of_rats=0;
no_of_rats=sum(df_dataset2['rat_arrival_number'].values);
print("total number of rats arrival is" , no_of_rats);


# Merge  dataset1 and dataset2
df_join_sample = pa.merge(df_dataset1, df_dataset2, on=['month'], how='inner')



#Data Wrangling



#delete null values
df_join_sample=df_join_sample.dropna();

#Write data to .csv file
df_join_sample.to_csv("dataset.csv");

#Delete bat_landing_number when rat_arrival_number is zero
df_join_sample=df_join_sample[df_join_sample['rat_arrival_number']!=0];

#Round 'food availability' column
df_join_sample['round_food_availability']=df_join_sample['food_availability'].round();


#Create boxplot of bat_landing_number (finding whether data sample has outliers or not)

sea.boxplot(df_join_sample['bat_landing_number']);
mat.title("before outliers removed");
mat.xlabel("bat landing number");
mat.show();

#Calulate lower and upper limit
Q1=nu.percentile(df_join_sample['bat_landing_number'],25);
Q3=nu.percentile(df_join_sample['bat_landing_number'],75);

IQR=Q3-Q1;
Lower_Limit=Q1-1.5*IQR;
Upper_Limit=Q3+1.5*IQR;

#Delete all zero value since we are not interested when bats are zero
df_join_sample=df_join_sample[df_join_sample['bat_landing_number']>0];


#Omitt outliers
df_join_sample=df_join_sample[df_join_sample['bat_landing_number']<=80];

#Create boxplot after omitting outliers
mat.title("after outliers has been removed");
mat.xlabel("bat landing number");
mat.boxplot(df_join_sample['bat_landing_number']);
mat.show();

#Re-creating dataframe with only specific variables
df_join_sample=df_join_sample[['habit','rat_arrival_number','round_food_availability','risk','season','reward','month','bat_landing_number']];

#Drop null values
df_join_sample=df_join_sample.dropna();


# Data Exploration


#Find coorelation
df_corr=df_join_sample.corr(numeric_only=True);

#Generate heatmap
df_heatmap=sea.heatmap(df_corr,center=0,annot=True);
mat.show();

#Generate differential statistics report
print(df_join_sample.describe());

#Displays number of rows and cols and display datatypes
print(df_join_sample.info());



#Visualizing data using scatter plot
mat.scatter(df_join_sample['month'],df_join_sample['bat_landing_number'],label='bat landing');
mat.scatter(df_join_sample['month'],df_join_sample['rat_arrival_number'],label='rat arrival');
mat.scatter(df_join_sample['month'],df_join_sample['risk'],label='risk');
mat.xlabel("month");
mat.legend();
mat.show();

#Divide data into spring and winter
df_winter_season=df_join_sample[df_join_sample["season"]==0];
df_spring_season=df_join_sample[df_join_sample["season"]==1];

#Divide data into risk and no risk
df_winter_season_risk=df_winter_season[df_winter_season['risk']==0];
df_winter_season_no_risk=df_winter_season[df_winter_season['risk']==1];

df_spring_season_risk=df_spring_season[df_spring_season['risk']==0];
df_spring_season_no_risk=df_spring_season[df_spring_season['risk']==1];

#Visualizing data using scatter plot
mat.scatter(df_winter_season['rat_arrival_number'],df_winter_season['bat_landing_number']);
mat.title("winter season");
mat.xlabel("rat arrival number");
mat.ylabel("bat landing number");
mat.show();
mat.scatter(df_spring_season['rat_arrival_number'],df_spring_season['bat_landing_number']);
mat.title("spring season");
mat.xlabel("rat arrival number");
mat.ylabel("bat landing number");
mat.show();




#Visualizing data using relplot

se.relplot(df_join_sample,x='rat_arrival_number',y='bat_landing_number',col='season',hue="round_food_availability");
mat.show();

#Drop null value
df_join_sample=df_join_sample.dropna();

# Build multiple linear regression model

#Seperate dependent and independent variables
X1=df_join_sample[['rat_arrival_number']];
Y1=df_join_sample['bat_landing_number'];

X2=df_join_sample[['round_food_availability']];
Y2=df_join_sample['bat_landing_number'];

X3=df_join_sample[['risk']];
Y3=df_join_sample['bat_landing_number'];

#Split X and Y samples into train and test samples
x1_train,x1_test,y1_train,y1_test=train_test_split(X1,Y1,train_size=0.40,random_state=0);

x2_train,x2_test,y2_train,y2_test=train_test_split(X2,Y2,train_size=0.40,random_state=0);

x3_train,x3_test,y3_train,y3_test=train_test_split(X3,Y3,train_size=0.40,random_state=0);

#Apply linear regression model
model1=LinearRegression();
model1.fit(x1_train,y1_train);

#Apply linear regression model
model2=LinearRegression();
model2.fit(x2_train,y2_train);

#Apply linear regression model
model3=LinearRegression();
model3.fit(x3_train,y3_train);

#Predict data from x_test and calculate mean
y1_predict=model1.predict(x1_test);
y1_base=nu.mean(y1_train);

#Predict data from x_test and calculate mean
y2_predict=model2.predict(x2_test);
y2_base=nu.mean(y2_train);

#Predict data from x_test and calculate mean
y3_predict=model3.predict(x3_test);
y3_base=nu.mean(y3_train);

# visualize data on scatter plot
mat.title("graph showing dependent bat landing number and independent rat arrival number ")
mat.xlabel("rat arrival number");
mat.ylabel("bat landing number");
mat.scatter(x1_test,y1_test);
mat.plot(x1_test,y1_predict);

mat.show();

# visualize data on scatter plot
mat.title("graph showing dependent bat landing number and independent rat arrival number ")
mat.xlabel("rat arrival number");
mat.ylabel("bat landing number");
mat.scatter(x2_test,y2_test);
mat.plot(x2_test,y2_predict);
mat.show();

# visualize data on scatter plot
mat.title("graph showing dependent bat landing number and independent rat arrival number ")
mat.xlabel("rat arrival number");
mat.ylabel("bat landing number");
mat.scatter(x3_test,y3_test);
mat.plot(x3_test,y3_predict);
mat.show();


#Seperate dependent and independent variables
X=df_join_sample[['rat_arrival_number','round_food_availability','risk']];
Y=df_join_sample['bat_landing_number'];

#Split X and Y samples into train and test samples
x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.40,random_state=0);

#Apply linear regression model
model=LinearRegression();
model.fit(x_train,y_train);


#Predict data from x_test and calculate mean
y_predict=model.predict(x_test);
y_base=nu.mean(y_train);


# Calculate mean absolute error, mean squared error, rooted mean squared error, normal rooted mean squared error
mae=metrics.mean_absolute_error(y_test,y_predict);
mse=metrics.mean_squared_error(y_test,y_predict);
rmse=ma.sqrt(mse);
nrmse=(rmse/(max(y_test)-min(y_test)));

print("mae is %f , mse is %f, rmse is %f, nrmse is %f " %(mae,mse,rmse,nrmse));

#Create base for the model
y_pred_base=[y_base]*len(y_test);
data_dictionary={"Actual":y_test,"Predicted":y_pred_base};
data_dataframe=pa.DataFrame(data_dictionary);
print(data_dataframe);

# Calculate mean absolute error, mean squared error, rooted mean squared error, normal rooted mean squared error
mae_base=metrics.mean_absolute_error(y_test,y_pred_base);
mse_base=metrics.mean_squared_error(y_test,y_pred_base);
rmse_base=ma.sqrt(mse);
nrmse_base=(rmse/(max(y_test)-min(y_test)));

print("mae_base is %f , mse_base is %f, rmse_base is %f, nrmse_base is %f " %(mae_base,mse_base,rmse_base,nrmse_base));

# visualize data on scatter plot
#mat.title("graph showing dependent bat landing number and independent rat arrival number ")
#mat.xlabel("rat arrival number");
#mat.ylabel("bat landing number");
#mat.scatter(x_test,y_test);
#mat.plot(x_test,y_predict);
#mat.plot(x_test,y_pred_base);
#mat.show();

# Seperate dependant and independent variables

X = df_join_sample[['rat_arrival_number', 'round_food_availability', 'risk']];
Y = df_join_sample['bat_landing_number'];

#Apply multiple linear regression

X=stat.add_constant(X);
x_model=stat.OLS(Y,X).fit();
pred=x_model.predict(X);
x_summary=x_model.summary();
print("  ");
print("  ");
print("  ");
print("******************************************")
print("orginal multiple linear regression model summary");
print("******************************************")
print("  ");
print("  ");
print("  ");
print(x_summary);
print("  ");
print("  ");
print("  ");
print("******************************************")

#Optimisation -1 create linearity

#Apply non-linear transformation
df_join_sample['rat_arrival_number_log']=df_join_sample['rat_arrival_number'].apply(nu.log);

df_join_sample=df_join_sample[['habit','rat_arrival_number','rat_arrival_number_log','round_food_availability','risk','season','reward','month','bat_landing_number']]

#Drop null values
df_join_sample=df_join_sample.dropna();

#Visualize the effect of the transformation
mat.scatter(df_join_sample['rat_arrival_number_log'],df_join_sample['bat_landing_number'],color='red');
mat.title(' transformed rat_arrival_number');
mat.xlabel('rat_arrival_number_log');
mat.ylabel('bat_landing_number');
mat.show();




#Re-run multiple linear regression with the transferred value

#Seperate dependant variable and independant variable
X=df_join_sample[['rat_arrival_number_log','round_food_availability','risk']];
Y=df_join_sample['bat_landing_number'];

#Build and evaluate multiple linear regression
X=stat.add_constant(X);
x_model=stat.OLS(Y,X).fit();
pred=x_model.predict(X);
x_summary=x_model.summary();
print("model after applying log tranform:")
print("******************************************")
print("  ");
print("  ");
print("  ");
print(x_summary);
print("  ");
print("  ");
print("  ");
print("******************************************")


#Optimisation-2 Power Transformer



#Seperate dependant and independant variable
X=df_join_sample[['rat_arrival_number','round_food_availability','risk']];
Y=df_join_sample['bat_landing_number'];



#Initialize and declare function
hold=PowerTransformer();

#Apply the transformer to make all explanatory variables for look like Bell_Curve
stan_x=hold.fit_transform(X.values);

#Restore columns and rows from X variable
stan_df=pa.DataFrame(stan_x,index=X.index,columns=X.columns);


#Create multiple linear Regression model
stan_df=stat.add_constant(stan_df);
model=stat.OLS(Y,stan_df).fit();
pred=model.predict(stan_df);
model_summary=model.summary();
print("model after Power Transformer  has been applied");
print("******************************************")
print("  ");
print("  ");
print("  ");
print(model_summary);
print("  ");
print("  ");
print("  ");
print("******************************************")


#Optimisation -3 Z-Score Transformation

#Seperate dependant and independant variable
X=df_join_sample[['rat_arrival_number','round_food_availability','risk']];
Y=df_join_sample['bat_landing_number'];


#Initialize and declare function
hold=StandardScaler();

#Apply Z-score transformation
stan_x=hold.fit_transform(X.values);

#Create dataframe which holds only independant variables
stan_df=pa.DataFrame(stan_x,index=X.index,columns=X.columns);

#Create Multiple linear Regression model:
stan_df=stat.add_constant(stan_df);
model=stat.OLS(Y,stan_df).fit();
pred=model.predict(stan_df);
model_summary=model.summary();
print("model after Z-Score Transformer  has been applied");
print("******************************************")
print("  ");
print("  ");
print("  ");
print(model_summary);
print("  ");
print("  ");
print("  ");
print("******************************************")

#Written By: Md Jahidul Islam Jisan
import os
import math
import argparse
import warnings
from dataclasses import dataclass
from typing import Tuple, Optional, Dict, Any, List

import numpy as np
import pandas as pd
from scipy import stats
from statsmodels.stats.proportion import proportions_ztest, proportion_confint

warnings.filterwarnings("ignore", category=RuntimeWarning)

# ----------------------------- Helpers -----------------------------

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip().lower() for c in df.columns]
    return df

def cohen_h(p1: float, p2: float) -> float:
    """Cohen's h for proportions (effect size)."""
    # guard for edge cases
    p1 = min(max(p1, 1e-9), 1-1e-9)
    p2 = min(max(p2, 1e-9), 1-1e-9)
    return 2 * (math.asin(math.sqrt(p1)) - math.asin(math.sqrt(p2)))

def rank_biserial_from_u(U: float, n1: int, n2: int) -> float:
    """Rank-biserial correlation from Mann-Whitney U."""
    return 1 - (2 * U) / (n1 * n2)

def cliffs_delta_from_u(U: float, n1: int, n2: int, sign: float) -> float:
    """Cliff's delta from U; sign determined by group medians difference."""
    delta = (2 * U) / (n1 * n2) - 1
    return math.copysign(abs(delta), sign)

def pick_two_seasons(df: pd.DataFrame, col: str = "season") -> Tuple[str, str]:
    """Prefer ('winter','spring') if available, otherwise pick top-2 most frequent."""
    seasons = df[col].dropna().astype(str).str.lower()
    uniq = seasons.unique().tolist()
    if "winter" in uniq and "spring" in uniq:
        return "winter", "spring"
    counts = seasons.value_counts()
    top2 = counts.index[:2].tolist()
    if len(top2) < 2:
        raise ValueError("Need at least two seasons for comparison.")
    return tuple(top2[:2])

def safe_median(x: pd.Series) -> float:
    x = x.dropna().astype(float)
    return float(np.median(x)) if len(x) else np.nan

def proportion_summary(x: pd.Series) -> Tuple[int, int, float]:
    """Returns (successes, n, p)."""
    x = x.dropna().astype(int)
    n = int(x.shape[0])
    k = int((x == 1).sum())
    p = (k / n) if n else np.nan
    return k, n, p

# ----------------------------- Test Runners -----------------------------

def compare_proportions_by_season(df: pd.DataFrame, binary_col: str, season_a: str, season_b: str,
                                  season_col: str = "season") -> Dict[str, Any]:
    subset = df[[season_col, binary_col]].dropna().copy()
    subset[season_col] = subset[season_col].astype(str).str.lower()
    subset[binary_col] = subset[binary_col].astype(int)

    g1 = subset[subset[season_col] == season_a][binary_col]
    g2 = subset[subset[season_col] == season_b][binary_col]
    k1, n1, p1 = proportion_summary(g1)
    k2, n2, p2 = proportion_summary(g2)

    if min(n1, n2) < 2:
        return {"ok": False, "reason": f"Too few observations for {binary_col} in one/both seasons."}

    stat, pval = proportions_ztest(count=[k1, k2], nobs=[n1, n2], alternative="two-sided")
    h = cohen_h(p1, p2)
    ci1 = proportion_confint(k1, n1, method="wilson")
    ci2 = proportion_confint(k2, n2, method="wilson")

    return {
        "ok": True,
        "test": "Two-proportion z-test",
        "variable": binary_col,
        "season_a": season_a, "season_b": season_b,
        "n_a": n1, "n_b": n2,
        "p_a": p1, "p_b": p2,
        "p_ci_a": ci1, "p_ci_b": ci2,
        "z": stat, "p_value": pval,
        "effect_size": float(h), "effect_name": "Cohen's h"
    }

def compare_continuous_by_season(df: pd.DataFrame, cont_col: str, season_a: str, season_b: str,
                                 season_col: str = "season") -> Dict[str, Any]:
    subset = df[[season_col, cont_col]].dropna().copy()
    subset[season_col] = subset[season_col].astype(str).str.lower()
    subset[cont_col] = pd.to_numeric(subset[cont_col], errors="coerce")
    subset = subset.dropna()

    g1 = subset[subset[season_col] == season_a][cont_col]
    g2 = subset[subset[season_col] == season_b][cont_col]

    n1, n2 = int(g1.shape[0]), int(g2.shape[0])
    if min(n1, n2) < 2:
        return {"ok": False, "reason": f"Too few observations for {cont_col} in one/both seasons."}

    # Use robust Mann-Whitney U (non-normal-friendly)
    U, pval = stats.mannwhitneyu(g1, g2, alternative="two-sided")
    med1, med2 = safe_median(g1), safe_median(g2)
    sign = np.sign(med1 - med2) if not np.isnan(med1) and not np.isnan(med2) else 1.0
    r_rb = rank_biserial_from_u(U, n1, n2)
    d_cliff = cliffs_delta_from_u(U, n1, n2, sign)

    return {
        "ok": True,
        "test": "Mann-Whitney U",
        "variable": cont_col,
        "season_a": season_a, "season_b": season_b,
        "n_a": n1, "n_b": n2,
        "median_a": float(med1), "median_b": float(med2),
        "U": float(U), "p_value": float(pval),
        "effect_size": float(d_cliff), "effect_name": "Cliff's delta",
        "rank_biserial": float(r_rb)
    }

# ----------------------------- Main -----------------------------

def main():
    ap = argparse.ArgumentParser(description="Investigation B — Inferential Analysis (Seasons)")
    ap.add_argument("--data-dir", type=str, default=".", help="Folder containing dataset1.csv and dataset2.csv")
    ap.add_argument("--season-a", type=str, default="", help="First season label to compare (e.g., winter)")
    ap.add_argument("--season-b", type=str, default="", help="Second season label to compare (e.g., spring)")
    args = ap.parse_args()

    d1_path = os.path.join(args.data_dir, "dataset1.csv")
    d2_path = os.path.join(args.data_dir, "dataset2.csv")
    if not os.path.exists(d1_path) or not os.path.exists(d2_path):
        raise SystemExit(f"Could not find dataset1.csv/dataset2.csv in {args.data_dir}")

    df1 = pd.read_csv(d1_path)
    df2 = pd.read_csv(d2_path)
    df1, df2 = normalize_cols(df1), normalize_cols(df2)

    # Make season lower-case string where present
    if "season" not in df1.columns:
        raise SystemExit("dataset1.csv must contain a 'season' column assigned by the zoologists.")
    df1["season"] = df1["season"].astype(str).str.lower()

    # Build a month->season map from dataset1 to tag dataset2 rows
    if "month" in df1.columns and "month" in df2.columns:
        month_map = (df1[["month", "season"]]
                     .dropna()
                     .drop_duplicates(subset=["month"])
                     .set_index("month")["season"]
                     .to_dict())
        if month_map:
            df2["season"] = df2["month"].map(month_map)
    # Determine comparison pair
    if args.season_a and args.season_b:
        season_a = args.season_a.strip().lower()
        season_b = args.season_b.strip().lower()
    else:
        season_a, season_b = pick_two_seasons(df1, "season")

    print(f"\nComparing seasons: {season_a!r} vs {season_b!r}\n")

    results: List[Dict[str, Any]] = []

    # --- Binary outcomes in dataset1 ---
    for bin_col in ["risk", "reward"]:
        if bin_col in df1.columns:
            out = compare_proportions_by_season(df1, bin_col, season_a, season_b, "season")
            out.update({"dataset": "dataset1"} if out.get("ok") else {})
            results.append(out)

    # --- Continuous outcomes in dataset1 ---
    for cont_col in ["bat_landing_to_food", "seconds_after_rat_arrival", "hours_after_sunset"]:
        if cont_col in df1.columns:
            out = compare_continuous_by_season(df1, cont_col, season_a, season_b, "season")
            out.update({"dataset": "dataset1"} if out.get("ok") else {})
            results.append(out)

    # --- Continuous outcomes in dataset2 (after season mapped from dataset1) ---
    if "season" in df2.columns:
        for cont_col in ["rat_arrival_number", "rat_minutes", "bat_landing_number"]:
            if cont_col in df2.columns:
                out = compare_continuous_by_season(df2, cont_col, season_a, season_b, "season")
                out.update({"dataset": "dataset2"} if out.get("ok") else {})
                results.append(out)
    else:
        results.append({"ok": False, "reason": "Could not map 'season' into dataset2 via 'month'. Skipping dataset2 tests."})

    # Assemble tidy table
    rows = []
    for r in results:
        if not r.get("ok"):
            rows.append({
                "dataset": r.get("dataset", ""),
                "variable": r.get("variable", ""),
                "test": r.get("test", ""),
                "season_a": r.get("season_a", ""),
                "season_b": r.get("season_b", ""),
                "p_value": np.nan,
                "effect": "",
                "note": r.get("reason", "N/A")
            })
            continue

        var = r["variable"]
        test = r["test"]
        sa, sb = r["season_a"], r["season_b"]
        pval = r.get("p_value", np.nan)
        eff = f"{r.get('effect_name','')}: {r.get('effect_size', np.nan):.3f}"

        # Make brief stat summary per test type
        if test == "Two-proportion z-test":
            stat_a = f"p={r['p_a']:.3f} (n={r['n_a']})"
            stat_b = f"p={r['p_b']:.3f} (n={r['n_b']})"
            note = f"95% CI A {tuple(round(x,3) for x in r['p_ci_a'])}, B {tuple(round(x,3) for x in r['p_ci_b'])}"
        else:  # Mann-Whitney
            stat_a = f"median={r['median_a']:.3f} (n={r['n_a']})"
            stat_b = f"median={r['median_b']:.3f} (n={r['n_b']})"
            note = f"U={r['U']:.1f}, rank-biserial={r['rank_biserial']:.3f}"

        rows.append({
            "dataset": r.get("dataset",""),
            "variable": var,
            "test": test,
            "season_a": sa, "season_b": sb,
            "stat_a": stat_a, "stat_b": stat_b,
            "p_value": pval,
            "effect": eff,
            "note": note
        })

    out_df = pd.DataFrame(rows)

    # Save results
    out_csv = "inferential_results.csv"
    out_md  = "inferential_results.md"
    out_df.to_csv(out_csv, index=False)

    # Markdown summary
    md_lines = ["# Investigation B — Inferential Results",
                "",
                f"Compared seasons: **{season_a}** vs **{season_b}**",
                "",
                "| dataset | variable | test | stat_a | stat_b | p_value | effect | note |",
                "|---|---|---|---|---|---:|---|---|"]
    for _, rr in out_df.iterrows():
        md_lines.append(
            f"| {rr.get('dataset','')} | {rr['variable']} | {rr['test']} | {rr.get('stat_a','')} | {rr.get('stat_b','')} | {rr['p_value']:.4f} | {rr.get('effect','')} | {rr.get('note','')} |"
        )
    with open(out_md, "w", encoding="utf-8") as f:
        f.write("\n".join(md_lines))

    print("\n=== Saved ===")
    print(f"- {out_csv}")
    print(f"- {out_md}")
    print("\nDone.")

if __name__ == "__main__":
    main()

